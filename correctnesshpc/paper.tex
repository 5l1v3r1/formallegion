\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables

% Dejavu fonts have unicode character support
\usepackage{DejaVuSansMono}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{listings} 
\usepackage{fancyvrb}

\usepackage{amssymb}
\usepackage{bbm}
\usepackage[greek,english]{babel}
\usepackage{textgreek}

%\usepackage{fontspec}
%\defaultfontfeatures{Ligatures=TeX}

\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{autofe}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\settopmatter{printacmref=false}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[Correctness'17]{Correctness 2017: First International Workshop on
  Software Correctness for HPC Applications}{November 2017}{Denver Colorado, USA} 
\acmYear{2017}
\copyrightyear{2017}

%\acmPrice{15.00}

\begin{document}

\title{Towards Correct Legion}
\author{George Stelle}
\affiliation{\institution{Los Alamos National Laboratory}}
\email{stelleg@lanl.gov}

\author{Noah Evans}
\affiliation{\institution{Sandia National Laboratories}}
\email{nevans@sandia.gov}

\author{Pat McCormick}
\affiliation{\institution{Los Alamos National Laboratory}}
\email{pat@lanl.gov}

\begin{abstract}
The heterogenity and massive scale of extreme scale systems are making the
traditional ad hoc implementation of programming models impractical. Formal
specification and verification of programming models is a promising approach to
ensuring correct behavior on heterogeneous systems at scales that would be
impractical for empirical verification. In this paper we formalize the
semantics of the Legion programming model which uses logical regions of memory
to reason about locality and concurrency in a mechanized proof assistant, Coq.
We then show how this enables formal reasoning about the model and prove
theorems about the semantics. We also discuss how to extend this work to prove
that serial semantics are preserved and how to extend the effort to provide a
complete proof of the correctness of its implementation.
\end{abstract}

\maketitle

\section{Introduction}
As High Performance Computing (HPC) systems run increasingly complex
simulations at increasingly large scales optimization of resource usage becomes
proportionally more important in terms of both economic efficiency and
scientific productivity. However the complexity of the interaction of the
different factors being optimized, such as power consumption, computational
intensity and I/O thoughput are outstripping the ability of individual
researchers to understand or debug empirically.

Given the importance of importance of HPC systems to issues of both national
and economic security, being able to efficiently and correctly specify,
develop, and validate these systems is an important research challenge with
impacts ranging from climate modeling to nuclear safety.

Formal specification and code proved by formal methods such as program logics
provide the strongest guarantees of correctness. Specifications describe how
a program should behave, while proofs show that a implementations conform to
their specifications. \emph{Formal} specifications and proofs are those that
have been embedded in a machine-checked formal logic
\cite{bertot2013interactive, nipkow2002isabelle, pfenning1999system,
jackson1994nuprl}. This process of formalizing specifications and proofs in
machine checked logics has been shown to catch common errors in previously
informal proofs, and therefore provide higher assurance of correctness than
alternative methods \cite{clarke1996formal, yang2011finding}.

In addition, recent work has shown that modular, composable formal
specifications enable formal correctness proofs for large software systems that
were previously thought unattainable \cite{weng2016deepspec}. By integrating a
formal specification tightly with an implementation, one can achieve the high
levels of confidence in a codes' adherence to its
specification\cite{weng2016deepspec}. For example, the Compcert project
provides a specification for the C language, implements it as series of
composed modules which are proved correct independently before being combined
into an optimizing C compiler. The success of Compcert in removing compiler
bugs has been well documented ~\cite{leroy2012compcert}. We will discuss later
how Compcert could be used in building verifiable HPC systems.

HPC programming models are particularly attractive target for these composable
specifications and verified implementations because of their importance 
ensuring that simulation codes stay maintainable, performant, and portable at
extreme scales\cite{diaz2012survey}.  We claim in particular that formalizing
programming models have wide ranging impact across the spectrum of HPC
application development --any composable correctness proofs can be leveraged
into proofs of correctness of every program using the model rather than having
to be reimplemented on a per application basis.

In this paper, we apply these composable specification and verification methods
to a recent programming model, Legion, by formalize its semantics and type
system in the Coq proof assistant. We then prove a few supporting lemmas as
examples of the kinds of things one can prove in an HPC settings. Finally, we
discuss the some of the possible paths towards a full, formally correct
implementation.

This paper makes the following contributions:
\begin{itemize}
  \item An analysis of the requirements for specifying and verifying an HPC
    programming model. 
  \item A formalization of the semantics of the Legion Programming Model in the
    Coq proof assistant.
  \item A description of a path to a fully verified programming model with provable
    correctness properties using soundness and completeness proofs.
  \item An exploration of the challenges to formally specifying the Legion runtime.
\end{itemize}

\section{Background}

Legion is an HPC programming model that enables
reasoning about locality and concurrency via logical regions of memory. It has
the attractive property that it is guaranteed to preserve serial semantics for
memory operations within logical regions. This allows programmers to avoid the
burden of reasoning about the non-determinism that arises from concurrent
computation. Specifically we'll be formalizating work on from Triecher et.
al \cite{treichler2013language}. While there has been subsequent work extending
Legion's capabilities, the core semantics of the Programming Model has stayed relatively stable
\cite{slaughter2015regent, treichler2016dependent}. 

By partitioning regions into \emph{subregions}, and tracking \emph{privileges},
Legion is able to ensure that certain code won't interfere or alias, and can
therefore be safely --at least with respect to those memory regions-- run in
parallel. This partitioning mechanism has been shown to be effective in enabling
applications to scale both on and off node~\cite{bauer2012legion,
treichler2014realm}. However subtle bugs still occur 
 in the implementation. One goal of this paper is to move towards
formally and systematically removing \emph{all} bugs from the programming
model, giving application developers and researcher quantifiable certainty that
their code correctly implements the semantics of the science being simulated.

Mechanized proof assistants provide one tool to reach this certainty.
Improvements to proof assistants over recent decades have made them a powerful
tool for implementing and reasoning about code. Recent research using proof
assistants has been able to verify the correctness of compilers~\cite{leroy2012compcert} and 
and operating systems~\cite{gu2011certikos}.

In particular, the Coq proof assistant has been effective for a variety of
verification tasks. Coq uses the Calculus of Inductive Constructions as its type 
theory allowing it to implement
a small dependently typed programming language and logic, capable of  
formal proofs of arbitrary mathematical objects\cite{bertot2013interactive}. In the last 10
years it has been used to both build systems via program extraction and prove
useful properties about them \cite{leroy2012compcert, anand2017certicoq,
chlipala2009effective}. 

To implement a specification of a Programming Model in a proof assistant like
Coq it is customary to specify that model as a set of inference rules describing
the typing rules (the 'Statics') which describe valid terms in the model and its
operational semantics (the 'Dynamics') which describe the valid state
transitions of the model. However, most Programming Models are not specified at
this level of detail. Many, like the OpenMP
specification, are very informal, primarily consisting of English descriptions
of how different constructs should behave \cite{dagum1998openmp}. Others, like
Legion's, are written by hand in the using standard notation for logical
relations for types and operational semantics with informal proofs based on these
rules. These approaches are contrasted to \emph{formal} specifications, 
which are specifications defined in a machine checkable formal logic, eg. Coq. 

The machine checkable proofs provided by these formal specifications make it
possible to encode both the natural language and logical specifications in a
formal language and verify the correctness in a manner analogous to type checking a program, exposing "bugs" in 
proofs and incompleteness in specifications. It is worth nothing, however, that
these that formal specifications and proofs implemented in proof assistant are
not infallible. Mistakes in specification can lead to incorrect assumptions and
behavior and the process of recognizing and correcting these inconsistencies is
an important part of the proving process.

\section{A Formal Specification of Legion}

Experience in the specification of programs and fixing bugs in those
specification has led to the aphorism that ``program without a specification cannot be incorrect, it can only be
surprising''\footnote{Paraphrase of J.J. Horning, 1982}. Its insight is that one
of the most
important and challenging aspects of proving correctness is defining a formal
specification of program behavior. Developing correct and modular specifications
is a subject of active research including the NSF DeepSpec
project\cite{deepspecnsf} which is exploring abstraction and composition
mechanisms for program specification. Particularly important in the development
of specifications is that the assumptions stated in a 
specification have far-reaching consequences in how easy it is to later prove
correctness properties. 

The Legion Programming Model provides an attractive target for formal
specification and verification because  --unique among high performance runtime systems-- Legion
provides a specification of its operational semantics \cite{treichler2013language}.
We take this specification of and formalize it in Coq, enabling us to prove
lemmas and theorems about it. Figure~\ref{syntax} provides a Coq
implementation of the syntax, and Figure~\ref{semantics} the semantics. All
code is available online at \texttt{https://github.com/lanl/formallegion}. 

\begin{figure}
\centering
\begin{BVerbatim}
Inductive e :=
  | bv : bool → e
  | iv : nat → e
  | etuple : list e → e
  | eindex : e → nat → e
  | id : var → e
  | new : T → r → e
  | null : T → r → e
  | isnull : e → e
  | upr : e → list r → e
  | downr : e → list r → e
  | read : e → e 
  | write : e → e → e
  | reduce : var → e → e
  | newcolor : r → e
  | color : e → e → e → e
  | add : e → e → e
  | lt : e → e → e
  | elet : var → T → e → e → e
  | eif : e → e → e → e
  | call : var → list r → list e → e
  | partition : r → e → list r → e → e
  | pack : e → T → list r → e
  | unpack : e → var → T → list r → e → e.
\end{BVerbatim}
\caption{Legion expression syntax}
\label{syntax}
\end{figure}

The Legion semantics are defined as a big step operational semantics, which
result in non-deterministic orderings of memory reads and writes. By defining a
notion of \texttt{valid\_interleaves}, we can reason formally about what evaluations 
can happen concurrently. This should allow us to prove formally that if the
runtime makes scheduling decisions based on region permissions in a particular
way, serial semantics are preserved with respect to the resulting heap state
and return value. This is a desirable property: it means that any code using
Legion can reason, either formally or informally, about its code with respect
to a simple serial semantics, and have those semantics be preserved for
parallel execution. This is in contrast to programming models like Cilk, which
claim a weaker property: a serial execution is one of many valid possible executions. 

\begin{figure*}
\centering
\begin{BVerbatim}
Reserved Notation " input ↦ output " (at level 50).
Inductive eval: Map r ρ 
              * Map var v
              * Map l T
              * Map l v
              * list l 
              * e 
              → v * list memop
              → Prop := 
  | ERead1 : ∀ M L H S C e l E v,
    (M, L, H, S, C, e) ↦ (vl l, E) →
    l ∉ C → 
    lookup l (apply E S) = Some v → 
    (M, L, H, S, C, read e) ↦ (v, E ++ [mread l v])
  | ERead2 : ∀ M L H S C e l E v,
    (M, L, H, S, C, e) ↦ (vl l, E) →
    l ∈ C → 
    (M, L, H, S, C, read e) ↦ (v, E ++ [mread l v]) 
  | EWrite : ∀ M L H S S' C e1 e2 l E1 E2 E v,
    (M, L, H, S, C, e1) ↦ (vl l, E1) →
    (M, L, H, S', C, e2) ↦ (v, E2) →
    valid_interleave S C E [E1; E2] →
    (M, L, H, S, C, write e1 e2) ↦ (vl l, E ++ [mwrite l v])
  | ENew : ∀ M L H S C t l r, 
    l ∈ lu r M →
    l ∉ domain S →
    (M, L, H, S, C, new t r) ↦ (vl l, [])
  | EUpRgn : ∀ M L H S C e v E rs,
    (M, L, H, S, C, e) ↦ (v, E) →
    (M, L, H, S, C, upr e rs) ↦ (v, E)
  | EColor : ∀ M L H S C K E1 E2 E3 E l e1 e2 e3 v, 
    (M, L, H, S, C, e1) ↦ (vcoloring K, E1) → 
    (M, L, H, apply E1 S, C, e2) ↦ (vl l, E2) → 
    (M, L, H, apply E2 (apply E1 S), C, e3) ↦ (viv v, E3) → 
    valid_interleave S C E [E1; E2; E3] →
    (M, L, H, S, C, color e1 e2 e3) ↦ (vcoloring ((l,v)::K), E) 
  | EPartition : ∀ M M' L H S C rs rp ρs e1 e2 K E' E1 E2 v, 
    (M, L, H, S, C, e1) ↦ (vcoloring K, E1) → 
    ρs = map (map fst) (groupBy (λ x y, beq_nat (snd x) (snd y)) K) →
    M' = zip rs ρs ++ M →  
    (M', L, H, S, C, e2) ↦ (v, E2) →
    valid_interleave S C E' [E1; E2] →
    (M, L, H, S, C, partition rp e1 rs e2) ↦ (v, E')  
  | ECall : ∀ M L H S C es vs Es xs id rs En1 E'' E' M' L' S' C' t ts rs' e Phi Q v, 
    (∀ e v E, In (e, (v, E)) (zip es (zip vs Es)) → (M, L, H, S, C, e) ↦ (v, E)) →
    valid_interleave S C E' Es →
    M' = zip rs' (map (λ r, lu r M) rs) →  
    L' = zip xs vs →
    S' = apply E' S → 
    function id rs xs ts Phi Q t e →
    (M', L', H, S', C', e) ↦ (v, En1) → 
    valid_interleave S C E'' [E'; En1] →
    (M, L, H, S, C, call id rs es) ↦ (v, E'')
    ...
where " input ↦ output " := (eval input output).
\end{BVerbatim}
\caption{Fragment of Legion's formal semantics defined in Coq}
\label{semantics}
\end{figure*}

The language is made up of some standard elements, e.g. \texttt{call},
\texttt{id}, and some Legion-specific constructs e.g. \texttt{partition},
\texttt{upr}. Evaluation is similar in nature, with the standard elements
having standard semantics with the addition that memory reads and writes must
be valid interleaves of subexpression memory operations. In simpler terms, only
orderings of memory operations that preserve the resulting memory structure are
permitted.

\section{Proofs}

While so far we have discussed the formalization of the \emph{specification},
we have largely left proofs undiscussed. In this section, we
discuss the challenges of proving useful properties of real world systems, and
give some examples of basic lemmas that will be useful in proving correctness
properties of Legion. The hope is that the reader will gain some insight into
the challenges involved in proving formal properties of systems of real-world
systems.

One of the core notions of Legion is the notion of region relations. These
describe how regions are related, either by being disjoint, or by being
subregions of one another. See Figure~\ref{regionrel} for the syntax. Another
important construction are mappers, \texttt{M}, which map logical regions
\texttt{r} to a set of physical locations. We include some definitions as
well, notably the notion that a mapping respects (\texttt{resp}) a set of
region requirements iff for every subregion relation and disjoint relation, the
mapping to sets of physical locations follows the corresponding set relation.

\begin{figure*}
\centering
\begin{BVerbatim}
Inductive ω := 
  | subr : r → r → ω 
  | disj : r → r → ω.
Definition Ω := set ω.

Reserved Notation " ω ∈* Ω " (at level 40).
Inductive cclo (Ω : Ω) : ω → Prop := 
  | trivial : ∀ ω, ω ∈ Ω → ω ∈* Ω
  | sub_refl : ∀ r, subr r r ∈* Ω
  | sub_trans : ∀ ri rj rk, subr ri rj ∈* Ω → subr rj rk ∈* Ω  → 
                                  subr ri rk ∈* Ω 
  | dis_sub : ∀ ri rj rk, subr ri rj ∈* Ω → disj rj rk ∈*  Ω → 
                                  disj ri rk ∈* Ω
  | dis_comm : ∀ ri rj, disj ri rj ∈* Ω → disj rj ri ∈* Ω 
where " ω ∈* Ω " := (cclo Ω ω).

Definition resp (M : M) (elem : Ω → ω → Prop) (Ω : Ω) :=
  (∀ r1 r2, elem Ω (subr r1 r2) → lu r1 M ⊆ lu r2 M)
                              ∧ 
  (∀ r1 r2, elem Ω (disj r1 r2) → lu r1 M ∩ lu r2 M = [])
.

Notation " M ~ Ω " := (resp M (λ Ω ω, In ω Ω) Ω) (at level 40).
Notation " M ~* Ω " := (resp M cclo Ω) (at level 40).
\end{BVerbatim}
\caption{Syntax for region relations}
\label{regionrel}
\end{figure*}

One important property to show when proving correctness of programs written the
Legion model is to show that relations are equivalent to their closure (ie. that
composed relations are equivalent to relations in isolation), especially with
respect memory locality. Figure~\ref{regionrelproof} provides a proof for this
assertion. Intuitively, this means that if a region is a
subregion of another region, and that region is a subregion of a third, then
the first subregion is a subregion of the third. Disjointness is commutative, 
and subregions of disjoint regions are disjoint. We've left out the Coq tactic
proofs for space, as they are likely less informative to the reader than the
propositions and definitions, but they can be found online as linked above. 
Lemma \texttt{resp\_clos\_sub} proves that given that if a subregion relation
holds with respect to a mapping \texttt{M} and a set of region constraints
\textOmega{Ω} for all regions \texttt{r1, r2} then holds for the closure of that
set of region constraints under that mapping. Given \texttt{resp\_clos\_sub}, 
Lemma \texttt{resp\_clos} proves that this implies that a mapping respects
a set of region constraints if and onlyo if it respects the closure of that
set. This non-trivial property is crucial for proving that the final decisions 
made by the tasking system based on the sets of constraints preserves 
serial semantics. 

\begin{figure}
\centering
\begin{BVerbatim}
Lemma resp_clos_sub : ∀ r1 r2 Ω (M:M), 
  (∀ r1 r2, subr r1 r2 ∈ Ω → lu r1 M ⊆ lu r2 M) → 
           subr r1 r2 ∈* Ω → lu r1 M ⊆ lu r2 M.

Lemma resp_clos : ∀ M Ω, M ~ Ω ↔ M ~* Ω.
\end{BVerbatim}
\caption{Lemmas about region relations}
\label{regionrelproof}
\end{figure}

\subsection{Specification Properties}
In addition to proving theorems and lemmas about the semantics of Legion as
they relate to HPC memory models, another goal of a formal specification is to
ensure both the completeness and soundness of the Core Legion model. Much of
the necessary implementation work here is ensuring that the entire grammar of
the language is both type safe and its operational semantics contain transition
rules for all productions in the language.

To do this we are writing our proofs of completeness and soundness (ie. that well
typed expressions evaluate to a value or diverge and that every transition in
the operational semantics produces a well typed value given a well typed
expression) together with our implementation of the semantics of the Core
Legion language.

Thus far this approach has acted as a sanity check for our implementation and
helped us handle unspecified corner cases in the Core Legion specification (eg.
the list of functions in the \texttt{T-Program} relation has no corresponding
transition in the operational semantics). 

The theorems we are using are described in Figure~\ref{soundnesstheorem} and
Figure~\ref{preservationtheorem} (see \texttt{https://github.com/lanl/formallegion}
for Coq versions of the proofs). 

\begin{figure}
\begin{BVerbatim}
Theorem preservation : ∀ e t E M L H S C T,
  ∃ v,
    eval M L H S C e v E →
    typing [] [] [] e T → 
    ∃ G P Ω, typing G P Ω v T.
\end{BVerbatim}
\caption{Preservation theorem}
\label{preservationtheorem}
\end{figure}

\begin{figure}
\begin{BVerbatim}
Theorem soundness : ∀ e t M H C T1 T2 L S,
  typing [] [] [] e T1  →
  (∃ E v,
    is_value v →
    eval M L H S C e v E).
\end{BVerbatim}
\caption{Soundness theorem}
\label{soundnesstheorem}
\end{figure}


\section{Future Work}

The work presented in this paper is a small fraction of the
amount of work required to build a complete, correct-by-construction HPC
application. In this section, we outline some of the possible paths towards
this goal. 

As mentioned earlier, one of the important characteristics of large formally
correct systems is modularity. This modularity has two purposes. On the one
hand, it enables ease of implementation. The second, analogous advantage, is
that modularity eases the burden of proofs. By defining
specifications as abstractions, one can separate proof concerns into proofs of
individual components or modules. For
example, by composing a proof that a program's serial semantics comply with a
formal specification with a proof that a parallel language respects those
serial semantics, it is possible derive a proof that a parallel program respects the
original formal semantics. In HPC, by applying this idea to parallel
programming models like Legion, we can separate the application developer from
having to prove correctness with respect to one or more increasingly complex,
heterogeneous architectures. Instead, we can provide an intermediate layer,
like Legion, that allows application developers to reason and prove correctness
to much simpler operational semantics, and then prove that those semantics are
retained even on the complex, heterogeneous architectures of today's
HPC Systems.

However modularly specifying HPC is not easy and is a challenging research
problem. We illustrate some of these difficulties in the following section.

\subsection{Current Limitations}

One common theme in formalizing systems is the discovery of issues in the
corresponding informal specification. For example, when formalizing the C
language for the CompCert project, Leroy et. al. found many cases where the
informal specification was simply incomplete \cite{leroy2012compcert}. Note
that this is separate notion from undefined behavior. Like unknown unknowns,
gaps in a specification can make it impossible to prove desired properties of a
system.  In contrast, undefined behavior is only a problem when programs
exihibit it.

In formalizing Legion, we have discovered that while there is a rich theory
ensuring that the side effects of concurrent evaluations preserve serial
semantics with respect to memory reads and writes, there is no theory for what
expressions can be evaluated concurrently based on value dependencies. For
example, if we define the program
\begin{center}
\begin{BVerbatim}
Definition read_write x y t T r :=
  elet x t (read (id y)) 
    (write (new T r) (id x)).
\end{BVerbatim}
\end{center}
then the semantics will happily order the \texttt{read} \emph{after} the
\texttt{write}, despite the fact that the value being written, \texttt{x},
generally will need to be read before being written. This inconsistency isn't catastrophic
for the semantics, the returned value and resulting heap are equivalent. 
 However it limits the ability to reason effectively about concurrency. 
In the actual implementations this is handled both dynamically with futures
and statically with dependency analysis \cite{slaughter2015regent}.

Another issue with the semantics as they are now is that there is no way to 
constrain ordering on side effects \emph{other than reads and writes into
regions}. For example, generally programs will need to make system calls or
foreign function calls in a particular order, and currently in the semantics
there is no support for enforcing such an ordering.

A third issue is that there is no way to dynamically create and destroy
regions. In other words, if the semantics assumes static memory allocation.
Of course, this differs from the actual implementation, and is an important,
though difficult, semantics to formalize. As memory hierarchies get more 
sophisticated, the need for tools for reasoning about memory use and locality
becomes more essential. 

A fourth challenge is that in practice, Legion is not a stand-alone language.
Instead, it is embedded in an existing language. For the current implementations, 
those languages are Regent and C/C++ \cite{slaughter2015regent}. There are two 
interesting paths towards addressing this issue. One is to build a sort of
abstraction for languages that Legion is embedded in, and prove correctness
with respect to that abstraction. This would likely be difficult to get right,
as capturing the important semantics of the languages that it would be embedded
in would likely be a significant challenge. A second possibility for addressing
this issue would be choosing a particular semantics and focusing on that. In
particular, combining the C API with the CompCert verified C work would likely
be a fruitful, though challenging, venture. 

All of these issues are addressable given enough time and effort. Some offer a
nice opportunity for modularity within the tasking formalization. For example,
ordering tasks based on dependencies of values is common accross all tasking
systems \cite{blumofe1995cilk, kaiser2014hpx}, and is likely a sort of
sub-semantics that they could all share, reducing proof burden across different
run-times.

\subsection{Performance}

In addition to semantic correctness, one important current area of research in
formal methods is formal
reasoning about performance \cite{mccarthy2017coq, chargueraud2015machine}. One
of the challenges for Legion, and runtime systems in general, is that the
scheduler often has a non-trivial amount of work to do, leading to large
overheads. In Legion, the combination of reasoning about permissions, memory
locality, etc., makes this overhead particularly hard to predict. 

This is one oft-overlooked advantage to formal reasoning: it allows reasoning
about \emph{any} property of a system, not just correctness. For example, there
is the work by \cite{mccarthy2017coq} working towards formally verified
complexity of code.  Chlipala et. al. have also used techniques like those
described here to construct and verify hardware description, where performance
must be reasoned about down to single cycles \cite{braibant2013formal}.  This
is one area where other tasking systems, like Cilk, are better understood than
Legion. Blumofe et al. informally describe bounds on runtime overheads, which
has been realized in practice as low overheads in the actual runtime
\cite{blumofe1995cilk}. 

Ideally, it would be possible to make similar claims about Legion runtime overheads.
Given a formal model of the work done by the runtime system, one can reason
about bounds on overhead. Currently, due to the complexity of the runtime
implementation, this is infeasible. Like some of the desired correctness
properties, a significant simplification of the runtime, and perhaps the
semantics, would likely be required to achieve such a goal.


\subsection{Other Tasking Systems}

Although the focus of this paper has been on the Legion Programming Model, there are other parallel programming systems
that offer exciting opportunities for formalization. While some, such as
 OpenMP, are likely much to large and complex to formalize without
significant research effort, others have simple enough semantics that formalization is
likely tractable.the Tapir project
\cite{schardl2017tapir} is a particularly attractive research target due to its simplicity
and the recent work on parallel extensions to LLVM. Building on existing formalization efforts for LLVM
\cite{zhao2012formalizing}, extending existing semantics with the Tapir instructions for
concurrency should be achievable in reasonable time despite challenges in
specifying its memory model.

As mentioned earlier, there is also the important concept of \emph{shared
semantics accross different tasking systems}. This notion of shared semantics
presents a valuable opportunity for modularization of specification. By defining
a shared semantics developers could reason more effectively, both formally and
informally, about the semantics of their code with respect to tasking layers.

\section{Conclusion}

In this paper, we have proposed a path to formally specifying HPC programming
models using mechanized proof assistants. To evaluate this proposal we have given a formal
semantics of the Legion Programming Model and proved its correctness regarding
memory interleavings between relations. We have also described mechanisms to
prove the soundness and completeness of our approach as well as the potential
difficulties in dealing with potential gaps in specification. Finally we
concluded by proposing the Tapir system as a viable next step in the
specification of HPC programming models.

\bibliographystyle{ACM-Reference-Format}
\bibliography{annotated}

\end{document}
